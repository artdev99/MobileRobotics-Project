{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3c8acf-b2c6-41ab-a0d1-c87bd9b0ff54",
   "metadata": {},
   "source": [
    "# Mobile Robotics Project \n",
    "## Groupe 47\n",
    "\n",
    "| Name      | SCIPER  |\n",
    "|-----------|---------|\n",
    "| Martin    | 340936  |\n",
    "| Laetitia  | 325743  |\n",
    "| Arthur    | 300443  |\n",
    "| Amandine  | 344736  |\n",
    "\n",
    "A **Jupyter notebook** which serves as a report. This must contain the information regarding :\n",
    "- The **members of the group**, it’s helpful to know who you are when we go over the report.\n",
    "- An **introduction to your environment** and to the **choices you made**.\n",
    "- Sections that go into a bit **more detail regarding the implementation** and are accompanied by the code required to **execute the different modules independently**. What is important is not to simply describe the code, which should be readable, but describe what is not in the code: the theory behind, the choices made, the measurements, the choice of parameters etc. Do not forget to **cite your sources** ! You can of course show how certain modules work in **simulation here, or with pre-recorded data**.\n",
    "- A section which is used to **run the overall project** and where we can see the path chosen, where the system believes the robot is along the path before and after filtering etc… This can also be done **in a .py file** if you prefer. Just make sure to reference it in the report so we can easily have a look at it.\n",
    "- Conclusion: The code used to execute the overall project. Do not hesitate to **make use of .py files** that you import in the notebook. The whole body of code does not have to be in the Jupyter notebook, on the contrary! Make sure the **code clean and well documented**. Somebody who starts to browse through it should easily understand what you are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017a0d7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "As part of the course Basics of mobile robotics, given to master students at EPFL by professor Mondada, we did a project using a Thymio and a camera. First, with computer vision, we map the environment where the Thymio will evolve, creating a grid based on the limits of the workspace and mapping global obstacles and the goal the robot has to reach. We localize the Thymio and find the shortest path he can follow to reach the goal without encountering any global obstacles. The Thymio then follows this path and can react to local obstcles added in front of him, avoiding them and continuing towards his goal. \n",
    "\n",
    "To do : describe the environment and the scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632b3905-510c-4c17-b2fd-de0d7d187d78",
   "metadata": {},
   "source": [
    "# Computer vision\n",
    "\n",
    "## ArUco marker\n",
    "### Detecting the bordures\n",
    "### Detecting the Thymio\n",
    "\n",
    "## Detection by color\n",
    "### Detecting the obstacles\n",
    "### Detecting the goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d7edf-9f55-438a-af60-dffc5b7987d7",
   "metadata": {},
   "source": [
    "# Kalman filter\n",
    "## Calculating the variances \n",
    "## Applying the filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce71db-804b-465f-a963-29f416dc6569",
   "metadata": {},
   "source": [
    "# Path planning\n",
    "## A* algorithm\n",
    "## Finding keypoints of the path\n",
    "\n",
    "Given the size of the Thymio compared to the size of the grid cells, we won't follow the path cell by cell but instead extract keypoints that will serve as intermediate goals for the Thymio.\n",
    "For cells every STEP cells, we study the vectors between the previous cell (STEP cells before) and the current cell, and between the current cell and the next cell (STEP cells after).\n",
    "We calculate how much the robot has to turn to change from the first direction to the second one, and if this angle surpasses a threshold (meaning the turn is non negligable), we add the current cell to the list of keypoints of the path. Even if the angles are found insignificant, a cell is added to the keypoints every few steps to make sure we don't ignore too many small changes of direction that could become significant when added together.\n",
    "\n",
    "In this algorithm we chose to study the path in steps of size STEP instead of considering every single one of the cells because the cells of the grid are very small compared to the Thymio. \n",
    "\n",
    "Using math.atan2(det, dot_product) allows us to find the signed angle between the two vectors. atan2() can find angles over the whole trigonometric circle (using the information given by the sign of the dot_product), not limiting itself to only two quadrants like atan()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1a6d26",
   "metadata": {},
   "source": [
    "# Motion control\n",
    "## Astolfi controller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceefd70",
   "metadata": {},
   "source": [
    "Diagram showing the thymio, the goal, and the variables used for the astolfi controller :\n",
    "\n",
    "<img src=\"schema_astolfi.jpg\" alt=\"Diagram\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc0b1a2-f685-45d0-81f6-65c5d967c263",
   "metadata": {},
   "source": [
    "We use an Astolfi controller to make the robot move towards his goal. We chose this kind of controller because it makes the Thymio moves more smoothly than advancing segment by segment and making the robot turn on itself between each segment. Indeed it makes a mix of both the wanted translational and rotational velocities to set the motors' speed :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6da952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snippet of code from the function motion_control(x,y,theta,x_goal,y_goal) in motion.py :\n",
    "\n",
    "v = k_rho*distance_to_goal                                  #translational velocity [cm/s]\n",
    "omega = k_alpha*(delta_angle) - k_beta*(delta_angle+theta)  #rotational velocity [rad/s]\n",
    "   \n",
    "#Calculate motor speed\n",
    "w_ml = (v+omega*L_AXIS)/R_WHEEL #[rad/s]\n",
    "w_mr = (v-omega*L_AXIS)/R_WHEEL #[rad/s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5330935",
   "metadata": {},
   "source": [
    "The translational and rotational velocities depend on the distance and angle to the goal, multiplied by the controllers parameters.\n",
    "We tuned the controllers parameters by testing. k_rho controls the translational velocity, k_alpha the rotational velocity, and k_beta is a damping term (to stabilize the robot's orientation when reaching the goal).\n",
    "\n",
    "We obtain motors' speed in rad/s, so before setting it to the thymio we scale it to fit the pwm, limit it (the thymio's motor can accept values ranging from -500 to 500), and convert them to integers (type accepted by the thymio). \n",
    "To find the scaling factor between the motors' speed in rad/s and the motors' target, we used the information given in the thymio cheat sheet : when the motors are set at 500, the translational velocity is equal to about 20cm/s. Therefore we obtain : \n",
    "\n",
    "SCALING_FACTOR = 500/(20*10^-2/R_WHEEL)\n",
    "\n",
    "(using R_WHEEL to convert m/s to rad/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed423277-caf3-4a6d-8c5b-91cd03d085ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "aw(node.lock())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56edd035-594d-4341-9183-48384e237620",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import cv2\n",
    "import numpy as np\n",
    "from libs.vision import *\n",
    "from skimage import feature, measure\n",
    "from scipy.spatial import distance\n",
    "import os\n",
    "from heapq import heappush, heappop\n",
    "import time\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Variables initialization\n",
    "Thymio_xytheta_hist = np.empty((0, 3))\n",
    "sigma = 5\n",
    "epsilon = 0.01\n",
    "thresh_obstacle = np.array([[4, 0, 90, 90, 90, 255]])  # Adjust thresholds if needed\n",
    "thresh_goal = np.array([30, 30, 20, 90, 120, 80])\n",
    "min_size = 500\n",
    "grid_size = 300\n",
    "Thymio_detected = False\n",
    "\n",
    "# Uncomment and adjust if using an IP camera\n",
    "\"\"\"\n",
    "print(\"Try to open camera\")\n",
    "\n",
    "login = \"thymio\"\n",
    "password = \"qwertz\"\n",
    "url = f\"https://{login}:{password}@192.168.21.126:8080/video\"  # Check the URL if needed\n",
    "cam = cv2.VideoCapture(url)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Try to open camera\")\n",
    "\n",
    "cam = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "\n",
    "if not cam.isOpened():\n",
    "    print(\"Camera could not be opened\")\n",
    "    cam.release()\n",
    "    exit()\n",
    "\n",
    "print(\"Warming up the camera...\")\n",
    "for _ in range(50):  # Number of frames to discard (adjust if needed)\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "# Initialization function\n",
    "image, grid, Thymio_xytheta, c_goal, path, obstacle_cnt, obstacle_cnt_expnded, goal_cnt, \\\n",
    "mat_persp, max_width_persp, max_height_persp, aruco_size = init(\n",
    "    cam, sigma, epsilon, thresh_obstacle, thresh_goal, min_size, grid_size, aruco=True)\n",
    "\n",
    "# Convert path coordinates for plotting\n",
    "path_img = grid1_coord2grid2_coord(path, grid, image)\n",
    "path_img = path_img[::-1]\n",
    "\n",
    "image_cnt = draw_cnt_image(\n",
    "    image, goal_cnt, obstacle_cnt, obstacle_cnt_expnded, path_img, Thymio_xytheta, c_goal, aruco_size,Thymio_detected)\n",
    "\n",
    "# Update history\n",
    "Thymio_xytheta_hist = np.vstack((Thymio_xytheta_hist, Thymio_xytheta))\n",
    "\n",
    "print(f\"Initialization time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "######################################################\n",
    "# UPDATE\n",
    "######################################################\n",
    "for steps in range(500):\n",
    "    start_time = time.time()\n",
    "    image, Thymio_xytheta, Thymio_detected = update_vision(\n",
    "        cam, sigma, epsilon, mat_persp, max_width_persp, max_height_persp)\n",
    "    if not Thymio_detected:\n",
    "        Thymio_xytheta = Thymio_xytheta_hist[-1, :]\n",
    "\n",
    "    image_cnt = draw_cnt_image(\n",
    "        image, goal_cnt, obstacle_cnt, obstacle_cnt_expnded, path_img, Thymio_xytheta, c_goal, aruco_size,Thymio_detected)\n",
    "\n",
    "    # Update history\n",
    "    Thymio_xytheta_hist = np.vstack((Thymio_xytheta_hist, Thymio_xytheta))\n",
    "\n",
    "    # Display the image and plots using cv2.imshow\n",
    "    cv2.imshow('Camera View', image_cnt)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    print(f\"Time for this step: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Clean up\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64a818f-33ba-463d-80a4-2e3b93fc83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the program\n",
    "aw(node.stop())\n",
    "aw(node.unlock())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
